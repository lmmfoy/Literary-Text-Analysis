{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment:\n",
    "\n",
    "Using the collocation module in nltk, find the bigrams and trigrams that occur three times or more in one of Austenâ€™s texts. Print their counts. Compare them to the collocations that are shown in Voyant for this text. Try to get yours as close to those in Voyant as possible by using stop words, window size, etc.\n",
    "\n",
    "Extra points if you can print the ngrams in order of frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"1815_Emma.txt\", \"r\") as f: \n",
    "    emmaString = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization using nltk library and its word_tokenize() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma',\n",
       " 'by',\n",
       " 'jane',\n",
       " 'austen',\n",
       " 'volume',\n",
       " 'i',\n",
       " 'chapter',\n",
       " 'i',\n",
       " 'emma',\n",
       " 'woodhouse']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "emmaTokens = nltk.word_tokenize(emmaString.lower()) #make the string lower case\n",
    "emmaTokens[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wanted to use the stopwords used in the default stopword list in Voyant to properly compare my results to those found using Voyant. Instead of importing the nltk stopwords and comparing the two, I decided to copy the Voyant stopwords into a text document, read them, and make them into a (lowercase) list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!', '$', '%', '&', '-', '.', '0', '1', '10', '100']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"Voyant_Stopwords.txt\", \"r\") as f:\n",
    "    stopwords = f.read()\n",
    "\n",
    "stopwords = stopwords.lower().split()\n",
    "stopwords[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used list comprehension to filter out any punctuation tokens that were left:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "emmaTokensCleaner = [word for word in emmaTokens if word[0].isalpha() \\\n",
    "                    and word not in stopwords] #if the word starts with a letter and it's not in stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I imported the nltk collocations module and looked for bigrams. Based on the  nltk documentation, it seems that the collocation window is counted differently than for Voyant. Voyant's window counts the words on either side of the keyword (so a window of 2 counts two words on either side) while the nltk window represents all the words counted (so a window of 5 counts two words on either side)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dr.', 'hughes'),\n",
       " ('mermaid', 'shark'),\n",
       " ('behold', 'monarch'),\n",
       " ('behold', 'seas'),\n",
       " ('caro', 'sposo'),\n",
       " ('kitty', 'frozen'),\n",
       " ('monarch', 'seas'),\n",
       " ('luxurious', 'selfish'),\n",
       " ('conjecture', 'conjectures'),\n",
       " ('gathering', 'strawberries'),\n",
       " ('husbands', 'wives'),\n",
       " ('friday', 'saturday'),\n",
       " ('proud', 'luxurious'),\n",
       " ('eating', 'drinking'),\n",
       " ('basin', 'gruel'),\n",
       " ('nicely', 'dressed'),\n",
       " ('frozen', 'maid'),\n",
       " ('kitty', 'maid'),\n",
       " ('lovely', 'reigns'),\n",
       " ('sore', 'throat')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.collocations import *\n",
    "\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "finder = BigramCollocationFinder.from_words(emmaTokensCleaner, 5) # window = 5 words \n",
    "finder.apply_freq_filter(3) # ignores collocations if they appear less than three times in corpus\n",
    "\n",
    "finder.nbest(bigram_measures.pmi, 20) #show 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I wanted to sort the bigrams by how frequently they appeared. I used this solution found on the internet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('mr.', 'knightley') 315\n",
      "('mrs.', 'weston') 253\n",
      "('mr.', 'elton') 230\n",
      "('mr.', 'weston') 190\n",
      "('miss', 'woodhouse') 177\n",
      "('mrs.', 'elton') 151\n",
      "('frank', 'churchill') 142\n",
      "('mr.', 'woodhouse') 141\n",
      "('miss', 'fairfax') 131\n",
      "('miss', 'bates') 119\n",
      "('jane', 'fairfax') 106\n",
      "('young', 'man') 90\n",
      "('said', 'emma') 82\n",
      "('mr.', 'mr.') 78\n",
      "('mr.', 'churchill') 73\n",
      "('miss', 'smith') 69\n",
      "('great', 'deal') 65\n",
      "('said', 'mr.') 64\n",
      "('miss', 'miss') 63\n",
      "('emma', 'mr.') 60\n"
     ]
    }
   ],
   "source": [
    "for bigram, frequency in sorted(finder.ngram_fd.items(), key=lambda f: f[1], reverse=True)[:20]: #sort by the second element, ie the frequency, from highest to lowest\n",
    "    print(bigram, frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are pretty close to the counts found in Voyant, but I can't get them  exactly the same even after playing around with window size. My guess is that the collocation algorithms are different between the two. \n",
    "\n",
    "Next I did the same as above with trigrams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fried', 'grease', 'roast'),\n",
       " ('cautious', 'advances', 'inch'),\n",
       " ('behold', 'monarch', 'seas'),\n",
       " ('approval', 'beam', 'soft'),\n",
       " ('shedding', 'nicely', 'dressed'),\n",
       " ('conundrum', 'reckon', 'low'),\n",
       " ('proud', 'luxurious', 'selfish'),\n",
       " ('agreed', 'conundrum', 'reckon'),\n",
       " ('kitty', 'frozen', 'maid'),\n",
       " ('modern', 'ease', 'disgusts'),\n",
       " ('angel', 'gesture', 'observe'),\n",
       " ('approval', 'beam', 'eye'),\n",
       " ('card-room', 'card-room', 'cards'),\n",
       " ('william', 'coxe', 'pert'),\n",
       " ('alphabet', 'express', 'perfection'),\n",
       " ('day', 'party.', 'professional'),\n",
       " ('fried', 'smallest', 'roast'),\n",
       " ('conjecture', 'aye', 'conjectures'),\n",
       " ('humours', 'house', 'large.'),\n",
       " ('sick', 'prosperity', 'indulgence')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Trigram_measures = nltk.collocations.TrigramAssocMeasures()\n",
    "finder = TrigramCollocationFinder.from_words(emmaTokensCleaner, 7) # window = 7 words\n",
    "finder.apply_freq_filter(3) \n",
    "\n",
    "finder.nbest(Trigram_measures.pmi, 20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('mr.', 'frank', 'churchill') 52\n",
      "('mr.', 'john', 'knightley') 37\n",
      "('mr.', 'elton', 'mr.') 36\n",
      "('mr.', 'knightley', 'mr.') 36\n",
      "('said', 'mr.', 'knightley') 31\n",
      "('mr.', 'mrs.', 'weston') 28\n",
      "('dear', 'miss', 'woodhouse') 27\n",
      "('mrs.', 'weston', 'emma') 27\n",
      "('mr.', 'mr.', 'knightley') 26\n",
      "('emma', 'mr.', 'knightley') 25\n",
      "('emma', 'mrs.', 'weston') 24\n",
      "('mr.', 'knightley', 'emma') 24\n",
      "('mr.', 'mr.', 'elton') 23\n",
      "('mr.', 'elton', 'harriet') 22\n",
      "('miss', 'woodhouse', 'miss') 21\n",
      "('said', 'mrs.', 'weston') 21\n",
      "('miss', 'smith', 'miss') 20\n",
      "('mrs.', 'weston', 'said') 20\n",
      "('emma', 'mr.', 'elton') 20\n",
      "('mrs.', 'miss', 'bates') 19\n"
     ]
    }
   ],
   "source": [
    "#sorting by frequency:\n",
    "\n",
    "for trigram, frequency in sorted(finder.ngram_fd.items(), key=lambda f: f[1], reverse=True)[:20]:\n",
    "    print(trigram, frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is the end of my assignment, but I wanted to play around with other things in nltk. I decided to try to filter out specific words that I didn't add to the stopwords list.\n",
    "\n",
    "First I tried a function that showed the raw frequency of the trigrams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('mr.', 'frank', 'churchill'), 0.0007748487396343374),\n",
       " (('mr.', 'john', 'knightley'), 0.00046161201510130733),\n",
       " (('dear', 'miss', 'woodhouse'), 0.0003956674415154063),\n",
       " (('said', 'mr.', 'knightley'), 0.00032972286792950524),\n",
       " (('mr.', 'mrs.', 'weston'), 0.00028026443774007944),\n",
       " (('oh', 'miss', 'woodhouse'), 0.00023080600755065366),\n",
       " (('mrs.', 'john', 'knightley'), 0.00021431986415417842),\n",
       " (('said', 'mrs.', 'weston'), 0.00021431986415417842),\n",
       " (('said', 'mr.', 'woodhouse'), 0.0001813475773612279),\n",
       " (('poor', 'miss', 'taylor'), 0.00014837529056827735),\n",
       " (('said', 'frank', 'churchill'), 0.00014837529056827735),\n",
       " (('colonel', 'mrs.', 'campbell'), 0.0001318891471718021),\n",
       " (('mr.', 'knightley', 'mr.'), 0.0001318891471718021),\n",
       " (('mrs.', 'miss', 'bates'), 0.0001318891471718021),\n",
       " (('fine', 'young', 'man'), 0.00011540300377532683),\n",
       " (('miss', 'smith', 'miss'), 0.00011540300377532683),\n",
       " (('said', 'mr.', 'weston'), 0.00011540300377532683),\n",
       " (('frank', 'churchill', 'miss'), 9.891686037885158e-05),\n",
       " (('miss', 'woodhouse', 'think'), 9.891686037885158e-05),\n",
       " (('poor', 'mr.', 'woodhouse'), 9.891686037885158e-05)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finder = TrigramCollocationFinder.from_words(emmaTokensCleaner)\n",
    "finder.score_ngrams(Trigram_measures.raw_freq)[:20] #Shows how frequent these trigrams are (I guess how much each occurs per word?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I used the length function to see how many trigrams had been found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59455"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(finder.score_ngrams(Trigram_measures.raw_freq)) #showing how many trigrams there are"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I applied word filters as shown in the nltk documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('said', 'frank', 'churchill'), 0.00014837529056827735),\n",
       " (('fine', 'young', 'man'), 0.00011540300377532683),\n",
       " (('amiable', 'young', 'man'), 8.243071698237631e-05),\n",
       " (('dare', 'say', 'shall'), 8.243071698237631e-05),\n",
       " (('great', 'deal', 'better'), 8.243071698237631e-05),\n",
       " (('know', 'dare', 'say'), 8.243071698237631e-05),\n",
       " (('said', 'emma', 'smiling'), 8.243071698237631e-05),\n",
       " (('said', 'john', 'knightley'), 8.243071698237631e-05),\n",
       " (('box', 'hill', 'party'), 6.594457358590106e-05),\n",
       " (('charming', 'young', 'man'), 6.594457358590106e-05),\n",
       " (('marrying', 'jane', 'fairfax'), 6.594457358590106e-05),\n",
       " (('said', 'emma', 'laughing'), 6.594457358590106e-05),\n",
       " (('saw', 'jane', 'fairfax'), 6.594457358590106e-05),\n",
       " (('talked', 'great', 'deal'), 6.594457358590106e-05),\n",
       " (('young', 'man', 'young'), 6.594457358590106e-05),\n",
       " (('bad', 'sore', 'throat'), 4.945843018942579e-05),\n",
       " (('behold', 'monarch', 'seas'), 4.945843018942579e-05),\n",
       " (('child', 'good', 'fortune'), 4.945843018942579e-05),\n",
       " (('day', 'box', 'hill'), 4.945843018942579e-05),\n",
       " (('fair', 'frozen', 'maid'), 4.945843018942579e-05)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finder.apply_word_filter(lambda w: w in (\"mr.\", \"mrs.\", \"miss\")) #I wanted to filter out these words\n",
    "finder.score_ngrams(Trigram_measures.raw_freq)[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Showing that there are fewer trigrams counted now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53432"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(finder.score_ngrams(Trigram_measures.raw_freq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Being able to remove words after seeing what the results are without having to go back and edit the stopword list could be useful.\n",
    "\n",
    "Then I decided to try this mystery sorting function, which ended up sorting the trigrams in alphabetical order, though I don't understand how:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('affection', 'sixteen', 'years'),\n",
       " ('ah', 'dear', 'perry'),\n",
       " ('amiable', 'young', 'man'),\n",
       " ('approval', 'beam', 'soft'),\n",
       " ('ask', 'frank', 'churchill'),\n",
       " ('bad', 'sore', 'throat'),\n",
       " ('barouche-landau', 'jane', 'fairfax'),\n",
       " ('bates', 'said', 'emma'),\n",
       " ('bates', 'said', 'great'),\n",
       " ('beam', 'soft', 'eye'),\n",
       " ('beautiful', 'little', 'friend'),\n",
       " ('became', 'perfectly', 'satisfied'),\n",
       " ('behold', 'monarch', 'seas'),\n",
       " ('believe', 'half', 'hour'),\n",
       " ('bends', 'slave', 'woman'),\n",
       " ('best', 'blessings', 'existence'),\n",
       " ('better', 'home', 'directly'),\n",
       " ('blushed', 'smiled', 'said'),\n",
       " ('boasted', 'power', 'freedom'),\n",
       " ('body', 'come', 'sit')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(finder.above_score(Trigram_measures.raw_freq, 1.0 /\n",
    "                         len(tuple(nltk.trigrams(emmaTokensCleaner)))))[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The End."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
