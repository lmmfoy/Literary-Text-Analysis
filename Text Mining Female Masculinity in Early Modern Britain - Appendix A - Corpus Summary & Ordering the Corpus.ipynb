{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Corpus Summary\n",
    "\n",
    "Using the PlaintextCorpusReader I counted the number of texts, tokens, words, and unique word types in my corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "\n",
    "corpus_root = \"WORKING_CORPUS_NORMALIZED\"\n",
    "corpusA = PlaintextCorpusReader(corpus_root, \".*txt\", encoding=\"ANSI\")\n",
    "\n",
    "# Encoding issue solved with info from: https://stackoverflow.com/questions/28802476/python-nltk-unicodedecodeerror-utf-8-codec-cant-decode-byte-0xe9-in-positio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1,019 files\n",
      "   100,292,197 tokens\n",
      "   82,703,346 words\n",
      "   1,060,594 unique word types\n"
     ]
    }
   ],
   "source": [
    "def corpus_summary(corpus):\n",
    "    print(\"  \", \"{:,}\".format(len(corpusA.fileids())), \"files\")\n",
    "    tokens = corpus.words()\n",
    "    print(\"  \", \"{:,}\".format(len(tokens)), \"tokens\")\n",
    "    words = [word for word in tokens if word[0].isalpha()]\n",
    "    print(\"  \", \"{:,}\".format(len(words)), \"words\")\n",
    "    print(\"  \", \"{:,}\".format(len(set(tokens))), \"unique word types\")\n",
    "    \n",
    "corpus_summary(corpusA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Ordering the Corpus\n",
    "\n",
    "In order to attach publishing dates to the texts and order the corpus, I made a dictionary from the metadata, made a function to return the date of the text when its name is used as input, and then looped through the files in the corpus folder appending the text's publishing date to the beginning of each filename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I converted the excel spreadsheet containing the corpus metadata into a csv file, then created a dictionary from the file \n",
    "\n",
    "import csv\n",
    "lines = []\n",
    "\n",
    "with open(\"EEBOTCP1csv.csv\", newline=\"\") as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        lines.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to bring up dates assigned to file IDs\n",
    "\n",
    "def find_date(idName):\n",
    "    for line in lines:\n",
    "        if line[\"TCP\"] in idName:\n",
    "            return line[\"Date\"]\n",
    "    return\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1533'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for example:\n",
    "find_date(\"A00525\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the directory\n",
    "import os\n",
    "directory = \"example\"\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1630\n",
      "A10018.headed.txt\n",
      "1636\n",
      "A10179.headed.txt\n",
      "1613\n",
      "A10338.headed.txt\n"
     ]
    }
   ],
   "source": [
    "# for loop finding the date of each file in the folder\n",
    "for filename in os.listdir(\"example\"):\n",
    "    date = find_date(filename)\n",
    "    print(date)\n",
    "    print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator.ADMINSO-GMMR8HL\\1 - LLCU-612 Notebooks\\1_FINAL_PROJECT\\example\\1630.A10018.headed.txt\n",
      "C:\\Users\\Administrator.ADMINSO-GMMR8HL\\1 - LLCU-612 Notebooks\\1_FINAL_PROJECT\\example\\1636.A10179.headed.txt\n",
      "C:\\Users\\Administrator.ADMINSO-GMMR8HL\\1 - LLCU-612 Notebooks\\1_FINAL_PROJECT\\example\\1613.A10338.headed.txt\n"
     ]
    }
   ],
   "source": [
    "# for loop finding the date for each text, then appending it to the filename\n",
    "for filename in os.listdir(\"example\"):\n",
    "    date = find_date(filename)\n",
    "    currentName = os.path.join(os.getcwd(), \"example\", filename) \n",
    "    newName = os.path.join(os.getcwd(), \"example\", date+'.'+filename) # adding date and a period to each filename\n",
    "    os.rename(currentName, newName)\n",
    "    print(newName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Most frequent words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_frequencies_corpusA = nltk.FreqDist(tokens_corpusA)\n",
    "word_frequencies_corpusA.most_common(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding female masculinity words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(corpusA.words(\"1540.A01349.norm.txt\").count(\"lady\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "files = glob.glob(\"test_corpus/*txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordCounts_inString(word):\n",
    "    totalWord = 0\n",
    "    for file in files:\n",
    "        f = open(file, \"r\")\n",
    "        textString = f.read()\n",
    "        f.close()\n",
    "        count = textString.lower().count(word.lower())\n",
    "        print(file, \":\", count)\n",
    "        totalWord += count\n",
    "    print(\"Total: \", totalWord)\n",
    "\n",
    "def wordCounts_inTokens(word):\n",
    "    #totalWord = 0\n",
    "    for file in files:\n",
    "        f = open(file, \"r\")\n",
    "        textString = f.read()\n",
    "        f.close()\n",
    "        tokens = nltk.word_tokenize(textString)\n",
    "        tokensLower = [word.lower() for word in tokens if word[0].isalpha() and word.lower() not in stopwords]\n",
    "        count = tokensLower.count(word.lower())\n",
    "        if count >0:\n",
    "            print(word, \":\", file, \":\", count)\n",
    "       # totalWord += count\n",
    "  #  print(\"Total: \", totalWord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\".female_masculinity_terms_1.txt\", \"r\") as f:\n",
    "    femaleMasculinityTerms1 = f.read()\n",
    "\n",
    "femMascList1 = femaleMasculinityTerms1.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = [\"god\", \"Christ\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "god : test_corpus\\1557.A20012.final.txt : 40\n",
      "god : test_corpus\\1577.A20020.final.txt : 69\n",
      "god : test_corpus\\1593.A20028.final.txt : 30\n",
      "god : test_corpus\\1599.A20021.final.txt : 13\n",
      "god : test_corpus\\1601.A20001.final.txt : 301\n",
      "god : test_corpus\\1602.A20029.final.txt : 4\n",
      "god : test_corpus\\1604.A20026.final.txt : 1\n",
      "god : test_corpus\\1604.A20027.final.txt : 1\n",
      "god : test_corpus\\1604.A20038.final.txt : 65\n",
      "god : test_corpus\\1626.A20002.final.txt : 2\n",
      "Christ : test_corpus\\1557.A20012.final.txt : 2\n",
      "Christ : test_corpus\\1577.A20020.final.txt : 2\n",
      "Christ : test_corpus\\1599.A20021.final.txt : 3\n",
      "Christ : test_corpus\\1601.A20001.final.txt : 384\n",
      "Christ : test_corpus\\1604.A20038.final.txt : 2\n"
     ]
    }
   ],
   "source": [
    "for word in list:\n",
    "    wordCounts_inTokens(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordPresence(word):\n",
    "    for file in files:\n",
    "        f = open(file, \"r\")\n",
    "        textString = f.read()\n",
    "        f.close()\n",
    "        tokens = nltk.word_tokenize(textString)\n",
    "        tokensLower = [word.lower() for word in tokens if word[0].isalpha() and word.lower() not in stopwords]\n",
    "        if word in tokensLower:\n",
    "            print(file, \"true\")\n",
    "        else:\n",
    "            print(file, \"false\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using the Corpus Reader \n",
    "\n",
    "corpus_root = \"test_corpus\"\n",
    "testCorpus = PlaintextCorpusReader(corpus_root, \".*txt\", encoding=\"ANSI\")\n",
    "\n",
    "def countWordsinText(word, filename):\n",
    "    tokens2 = testCorpus.words(filename)\n",
    "    wordOccurrences = [token for token in tokens2 if token.lower() == word.lower()]\n",
    "    numOccurrences = len(wordOccurrences)\n",
    "    return numOccurrences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countWordsinText(\"lady\", \"1557.A20012.headed.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
